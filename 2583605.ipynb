{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨新人赛：钢铁缺陷检测挑战赛-第10名方案\n",
    "[比赛链接](https://aistudio.baidu.com/aistudio/competition/detail/114) https://aistudio.baidu.com/aistudio/competition/detail/114\n",
    "\n",
    "###  过程：\n",
    "1.使用了faster-rcnn, 训练了300个epoches, 检测结果用了threshold<0.5 去除检测框， 分数36分左右（这里提交csv有个小插曲, 就是检测结果必须按照image_id的顺序排列， 后台判分就是按照image_id来判分的）\n",
    "\n",
    "2. 参照别人的经验，使用ppyolo v2的模型， 训练500 epoches, 使用threshold<0.05 去除检测框,分数42.06\n",
    "尝试平均两个模型结果， 分数<36\n",
    "直接拼接两个模型结果，分数<36\n",
    "\n",
    "###  感受：\n",
    "后面工作比较忙就没有继续提升了。还是要赞一下paddle平台， 恢复训练会继续上一次epoches往下计数(也就是lr 也是延续原来的策略)， 对比我之前用一些github上的源码工程， 恢复训练总是会重新计数，就很蠢。 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PaddleDetection'...\n",
      "remote: Enumerating objects: 18212, done.\u001b[K\n",
      "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
      "remote: Total 18212 (delta 15), reused 38 (delta 12), pack-reused 18162\u001b[K\n",
      "Receiving objects: 100% (18212/18212), 181.60 MiB | 11.27 MiB/s, done.\n",
      "Resolving deltas: 100% (13158/13158), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PaddlePaddle/PaddleDetection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 对数据集进行分析统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting lxml\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/97/d4/156d939ca782193b4eb46e53b1df5f003a9fe21d0d5233ce014c7e957ae1/lxml-4.6.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5MB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.6.4\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anno_set ['rolled-in_scale', 'patches', 'crazing', 'pitted_surface', 'inclusion', 'scratches']\r\n",
      "num_list [493, 679, 537, 339, 788, 420]\r\n"
     ]
    }
   ],
   "source": [
    "!python  ~/work/analyse_voc.py\r\n",
    "#0.3， 0.5， 1， 2， 4， 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load data annotations on: ./data/widerface-annotations\r\n",
      "Start to do kmeans, please wait for a moment.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/aistudio/work/object-detection-anchors/example.py\", line 104, in <module>\r\n",
      "    out = kmeans(data, k=CLUSTERS)\r\n",
      "  File \"/home/aistudio/work/object-detection-anchors/kmeans.py\", line 72, in kmeans\r\n",
      "    clusters = boxes[np.random.choice(rows, k, replace=False)]\r\n",
      "  File \"mtrand.pyx\", line 903, in numpy.random.mtrand.RandomState.choice\r\n",
      "ValueError: a must be greater than 0 unless no samples are taken\r\n"
     ]
    }
   ],
   "source": [
    "!python  ~/work/object-detection-anchors/example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用x2coco.py文件将voc格式转化为coco(失败)\r\n",
    "!python ~/work/PaddleX-develop/paddlex/tools/dataset_conversion/x2coco.py \\\r\n",
    "#!python work/x2coco.py \\\r\n",
    "--dataset_type voc \\\r\n",
    "--image_input_dir work/train/IMAGES \\\r\n",
    "--voc_anno_dir Pwork/train/ANNOTATIONS \\\r\n",
    "#--voc_anno_list PaddleDetection/dataset/VOC2012/ImageSets/Main0/test.txt \\\r\n",
    "#--voc_label_list PaddleDetection/dataset/VOC2012/ImageSets/Main/label_list.txt \\\r\n",
    "--output_dir work/coco/train \\\r\n",
    "--voc_out_name 'test.json'\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 准备配置文件\n",
    "\n",
    "PaddleX的使用需要提供分类标签文件`label.txt`\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ec19891595a34046937b165922cfaed0928ee30ea4704555b25a2e94ea01d64e)\n",
    "\n",
    "以及图片-xml的链接文件`train_list.txt` `val_list.txt`，分别用于验证和训练\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1de87d9972e44eb0b1136a21590c0ffd4a0c5f38b47a4433aa07583b589dca5b)\n",
    "\n",
    "下面将遍历训练图片并生成对应的`train_list.txt` `val_list.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压文件并移除多余的目录\r\n",
    "! unzip work/train.zip -d ./work/\r\n",
    "! rm -f -r work/__MACOSX\r\n",
    "! unzip work/test.zip -d ./work/\r\n",
    "! rm -f -r work/__MACOSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "%cd /home/aistudio/\r\n",
    "# 遍历训练集\r\n",
    "name = [name for name in os.listdir('work/train/IMAGES') if name.endswith('.jpg')]\r\n",
    "\r\n",
    "train_name_list=[]\r\n",
    "for i in name:\r\n",
    "    # Tag:\r\n",
    "    tmp = os.path.splitext(i)\r\n",
    "    train_name_list.append(tmp[0])\r\n",
    "\r\n",
    "# 构造图片-xml的链接文件ori_train.txt\r\n",
    "with open(\"./work/train/ori_train.txt\",\"w\") as f:\r\n",
    "    for i in range(len(train_name_list)):\r\n",
    "        if i!=0: f.write('\\n')\r\n",
    "        line='IMAGES/'+train_name_list[i]+'.jpg'+\" \"+\"ANNOTATIONS/\"+train_name_list[i]+'.xml' \r\n",
    "        f.write(line)\r\n",
    "\r\n",
    "# 构造label.txt\r\n",
    "labels=['crazing','inclusion','pitted_surface','scratches','patches','rolled-in_scale']\r\n",
    "with open(\"./work/train/labels.txt\",\"w\") as f:\r\n",
    "    for i in range(len(labels)):\r\n",
    "        line=labels[i]+'\\n'\r\n",
    "        f.write(line)\r\n",
    "\r\n",
    "# 将ori_train.txt随机按照eval_percent分为验证集文件和训练集文件\r\n",
    "# eval_percent 验证集所占的百分比\r\n",
    "import random\r\n",
    "eval_percent=0.2;\r\n",
    "\r\n",
    "data=[]\r\n",
    "with open(\"work/train/ori_train.txt\", \"r\") as f:\r\n",
    "    for line in f.readlines():\r\n",
    "        line = line.strip('\\n')\r\n",
    "        data.append(line)\r\n",
    "\r\n",
    "index=list(range(len(data)))\r\n",
    "random.shuffle(index)\r\n",
    "\r\n",
    "# 构造验证集文件\r\n",
    "cut_point=int(eval_percent*len(data))\r\n",
    "with open(\"./work/train/val_list.txt\",\"w\") as f:\r\n",
    "    for i in range(cut_point):\r\n",
    "        if i!=0: f.write('\\n')\r\n",
    "        line=data[index[i]]\r\n",
    "        f.write(line)\r\n",
    "\r\n",
    "# 构造训练集文件\r\n",
    "with open(\"./work/train/train_list.txt\",\"w\") as f:\r\n",
    "    for i in range(cut_point,len(data)):\r\n",
    "        if i!=cut_point: f.write('\\n')\r\n",
    "        line=data[index[i]]\r\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "%cd /home/aistudio/\r\n",
    "# 遍历训练集\r\n",
    "name = [name for name in os.listdir('work/test/IMAGES') if name.endswith('.jpg')]\r\n",
    "\r\n",
    "train_name_list=[]\r\n",
    "for i in name:\r\n",
    "    tmp = os.path.splitext(i)\r\n",
    "    train_name_list.append(tmp[0])\r\n",
    "\r\n",
    "# 构造图片-xml的链接文件ori_train.txt\r\n",
    "with open(\"./work/test/val_list.txt\",\"w\") as f:\r\n",
    "    for i in range(len(train_name_list)):\r\n",
    "        if i!=0: f.write('\\n')\r\n",
    "        line='IMAGES/'+train_name_list[i]+'.jpg'+\" \"+\"ANNOTATIONS/\"+train_name_list[i]+'.xml' \r\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 正式进行训练工作\n",
    "### 使用--eval 会默认每训练完一个epoch就对验证集进行一次预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleDetection\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting scikit-image\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9a/44/8f8c7f9c9de7fde70587a656d7df7d056e6f05192a74491f7bc074a724d0/scikit_image-0.19.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.3MB)\n",
      "\u001b[K     |████████████████████████████████| 13.3MB 8.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image) (1.20.3)\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d8/38/85ae5ed77598ca90558c17a2f79ddaba33173b31cf8d8f545d34d9134f0d/tifffile-2021.11.2-py3-none-any.whl (178kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image) (1.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image) (20.9)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image) (7.1.2)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a1/9c/564511b6e1c4e1d835ed2d146670436036960d09339a8fa2921fe42dad08/PyWavelets-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (6.1MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2MB 5.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging>=20.0->scikit-image) (2.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.2->scikit-image) (4.4.2)\n",
      "Installing collected packages: tifffile, PyWavelets, scikit-image\n",
      "Successfully installed PyWavelets-1.2.0 scikit-image-0.19.1 tifffile-2021.11.2\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (4.36.1)\n",
      "Collecting typeguard (from -r requirements.txt (line 2))\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9a/bb/d43e5c75054e53efce310e79d63df0ac3f25e34c926be5dffb7d283fb2a8/typeguard-2.13.3-py3-none-any.whl\n",
      "Requirement already satisfied: visualdl>=2.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.1.1.26)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (5.1.2)\n",
      "Collecting shapely (from -r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/20/33ce377bd24d122a4d54e22ae2c445b9b1be8240edb50040b40add950cd9/Shapely-1.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.6.3)\n",
      "Collecting terminaltables (from -r requirements.txt (line 8))\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c4/fb/ea621e0a19733e01fe4005d46087d383693c0f4a8f824b47d8d4122c87e0/terminaltables-3.1.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Cython in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (0.29)\n",
      "Collecting pycocotools (from -r requirements.txt (line 10))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2e/1c/4fd663fc57be418cecf6f89d0d141ffa815d0fd6538ccddeccf767e8aace/pycocotools-2.0.3.tar.gz (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 426kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=42.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (56.2.0)\n",
      "Collecting lap (from -r requirements.txt (line 13))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (0.0)\n",
      "Collecting motmetrics (from -r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9c/28/9c3bc8e2a87f4c9e7b04ab72856ec7f9895a66681a65973ffaf9562ef879/motmetrics-1.2.0-py3-none-any.whl (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: openpyxl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r requirements.txt (line 16)) (3.0.5)\n",
      "Collecting cython_bbox (from -r requirements.txt (line 17))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fa/b9/fc7d60e8c3b29cc0ff24a3bb3c4b7457e10b7610fbb2893741b623487b34/cython_bbox-0.1.3.tar.gz (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.8MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (0.8.53)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (1.21.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (3.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (2.22.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (3.14.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (1.20.3)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (0.7.1.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (1.1.5)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.0->-r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sklearn->-r requirements.txt (line 14)) (0.24.2)\n",
      "Collecting xmltodict>=0.12.0 (from motmetrics->-r requirements.txt (line 15))\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
      "Collecting pytest (from motmetrics->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/76/86f886e750b81a4357b6ed606b2bcf0ce6d6c27ad3c09ebf63ed674fc86e/pytest-6.2.5-py3-none-any.whl (280kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 998kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flake8-import-order (from motmetrics->-r requirements.txt (line 15))\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ab/52/cf2d6e2c505644ca06de2f6f3546f1e4f2b7be34246c9e0757c6048868f9/flake8_import_order-0.18.1-py2.py3-none-any.whl\n",
      "Collecting pytest-benchmark (from motmetrics->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2c/60/423a63fb190a0483d049786a121bd3dfd7d93bb5ff1bb5b5cd13e5df99a7/pytest_benchmark-3.4.1-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 210kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jdcal in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->-r requirements.txt (line 16)) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->-r requirements.txt (line 16)) (1.0.1)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.0->-r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.0->-r requirements.txt (line 3)) (3.9.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.1.0->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.1.0->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.1.0->-r requirements.txt (line 3)) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.8.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (1.3.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (0.23)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (16.7.9)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (1.4.10)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.0->-r requirements.txt (line 3)) (0.6.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.0->-r requirements.txt (line 3)) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.0->-r requirements.txt (line 3)) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.0->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.11.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.0->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.0->-r requirements.txt (line 3)) (7.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.0->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.0->-r requirements.txt (line 3)) (2.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 14)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 14)) (0.14.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->-r requirements.txt (line 15)) (19.2.0)\n",
      "Collecting iniconfig (from pytest->motmetrics->-r requirements.txt (line 15))\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9b/dd/b3c12c6d707058fa947864b67f0c4e0c39ef8610988d7baea9578f3c48f3/iniconfig-1.1.1-py2.py3-none-any.whl\n",
      "Collecting py>=1.8.2 (from pytest->motmetrics->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f6/f0/10642828a8dfb741e5f3fbaac830550a518a775c7fff6f04a007259b0548/py-1.11.0-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 1.5MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->-r requirements.txt (line 15)) (0.13.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->-r requirements.txt (line 15)) (20.9)\n",
      "Collecting py-cpuinfo (from pytest-benchmark->motmetrics->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 1.3MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl>=2.1.0->-r requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.1.0->-r requirements.txt (line 3)) (1.1.1)\n",
      "Building wheels for collected packages: pycocotools, lap, cython-bbox, py-cpuinfo\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.3-cp37-cp37m-linux_x86_64.whl size=273726 sha256=d6cdea791343cd506ae86ccd6557916255baa647d41e25cf588850ab28a1c685\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/50/c3/cc/b58f5739a7766a3a0b445934ef76c4161719abb878c3c77070\n",
      "  Building wheel for lap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1593866 sha256=6e846dc4365c140d23fa47fa887c5ffc4e6e1700181ff7577f5ad26b37e8e11c\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/66/b9/1a/5c513d0b33edd38e4b95052909201336e6526c65226044faff\n",
      "  Building wheel for cython-bbox (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cython-bbox: filename=cython_bbox-0.1.3-cp37-cp37m-linux_x86_64.whl size=61619 sha256=35b3545ee870a51f5e05525b8ee54b476dbebe36bb93b3758ea3a3b796bc47e3\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/c6/f5/f6/95f480963fc23fc8adf314aa715e38669c00c04636a89a69ac\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=e404e3e3b8c4d4e721fee7f9384bdc1b8670f685e7f8ae996c67594e349ec50c\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/6e/ad/c2/8f2580a65eaae741237aede048de6f6c019874e25dbaddfe14\n",
      "Successfully built pycocotools lap cython-bbox py-cpuinfo\n",
      "Installing collected packages: typeguard, shapely, terminaltables, pycocotools, lap, xmltodict, iniconfig, py, pytest, flake8-import-order, py-cpuinfo, pytest-benchmark, motmetrics, cython-bbox\n",
      "Successfully installed cython-bbox-0.1.3 flake8-import-order-0.18.1 iniconfig-1.1.1 lap-0.4.0 motmetrics-1.2.0 py-1.11.0 py-cpuinfo-8.0.0 pycocotools-2.0.3 pytest-6.2.5 pytest-benchmark-3.4.1 shapely-1.8.0 terminaltables-3.1.10 typeguard-2.13.3 xmltodict-0.12.0\n"
     ]
    }
   ],
   "source": [
    "#安装依赖\r\n",
    "%cd PaddleDetection/\r\n",
    "!pip install scikit-image\r\n",
    "!pip install -r requirements.txt\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/16 04:04:45] ppdet.engine INFO: Best test bbox ap is 0.983.\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\n!python -u tools/train.py     -c /home/aistudio/PaddleDetection/configs/faster_rcnn/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x.yml     --use_vdl=True     --vdl_log_dir=vdl_dir/scalar     --eval\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd PaddleDetection/\r\n",
    "%env CUDA_VISIBLE_DEVICES=0\r\n",
    "# -c /home/aistudio/PaddleDetection/configs/faster_rcnn/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x.yml \\\r\n",
    "#使用visualDL记录曲线变化\r\n",
    "!python -u tools/train.py \\\r\n",
    "    -c /home/aistudio/PaddleDetection/configs/ppyolo/ppyolov2_r50vd_dcn_voc.yml\\\r\n",
    "    --use_vdl=True \\\r\n",
    "    --vdl_log_dir=vdl_dir/scalar \\\r\n",
    "    -r output/ppyolov2_r50vd_dcn_voc/331.pdparams \\\r\n",
    "    --eval \r\n",
    "    \r\n",
    "'''    \r\n",
    "!python -u tools/train.py \\\r\n",
    "    -c /home/aistudio/PaddleDetection/configs/faster_rcnn/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x.yml \\\r\n",
    "    --use_vdl=True \\\r\n",
    "    --vdl_log_dir=vdl_dir/scalar \\\r\n",
    "    --eval\r\n",
    "'''\r\n",
    "    #-r output/faster_rcnn_r50_fpn_2x/22000.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 手动对验证集进行预测\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PaddleDetection/'\n",
      "/home/aistudio/PaddleDetection\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/openpyxl/compat/numbers.py:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  numpy.float,\n",
      "Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly\n",
      "W1215 18:17:04.229130  3429 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1215 18:17:04.234138  3429 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "[12/15 18:17:12] ppdet.utils.checkpoint INFO: Finish loading model weights: output/ppyolov2_r50vd_dcn_voc/82.pdparams\n",
      "[12/15 18:17:12] ppdet.engine INFO: Eval iter: 0\n",
      "[12/15 18:17:23] ppdet.metrics.metrics INFO: Accumulating evaluatation results...\n",
      "[12/15 18:17:23] ppdet.metrics.metrics INFO: mAP(0.50, 11point) = 65.73%\n",
      "[12/15 18:17:23] ppdet.engine INFO: Total sample number: 280, averge FPS: 24.850948284691086\n"
     ]
    }
   ],
   "source": [
    "%cd PaddleDetection/\r\n",
    "# !python tools/eval.py \\\r\n",
    "#     -c /home/aistudio/PaddleDetection/configs/faster_rcnn/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x.yml \\\r\n",
    "#     -o weights=output/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x/model_final.pdparams \\\r\n",
    "#     save_prediction_only=True\r\n",
    "\r\n",
    "# o weights=output/ppyolov2_r50vd_dcn_voc/best_model.pdparams \\\r\n",
    "!python tools/eval.py \\\r\n",
    "    -c /home/aistudio/PaddleDetection/configs/ppyolo/ppyolov2_r50vd_dcn_voc.yml \\\r\n",
    "    -o weights=output/ppyolov2_r50vd_dcn_voc/82.pdparams \\\r\n",
    "    save_prediction_only=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 对test集进行推理预测， \n",
    "1. 对测试集生成一份假的json标注文件（test测试集本身没有标注）\n",
    "2. 这里修改了Paddle Detection 的源码tools/infer.py与engine/ppdet/trainer.py, 修改是为了把预测结果输出为一个json文件\n",
    "(参考链接：https://blog.csdn.net/qq_40502460/article/details/117826384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "4\r\n",
      "5\r\n",
      "6\r\n"
     ]
    }
   ],
   "source": [
    "!python ~/work/generate_fake_test_json.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############对eval 测试集！！！\r\n",
    "%cd PaddleDetection/\r\n",
    "!python tools/infer.py -c /home/aistudio/PaddleDetection/configs/faster_rcnn/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x.yml \\\r\n",
    "                    --infer_dir=/home/aistudio/work/train/eval \\\r\n",
    "                    --output_dir=infer_output_eval/ \\\r\n",
    "                    --draw_threshold=0.5 \\\r\n",
    "                    -o weights=output/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x/model_final.pdparams  \\\r\n",
    "                    --save_txt=True\r\n",
    "                    #--use_vdl=Ture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PaddleDetection/'\n",
      "/home/aistudio/PaddleDetection\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/openpyxl/compat/numbers.py:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  numpy.float,\n",
      "Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly\n",
      "W1217 00:22:29.703610 11033 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1217 00:22:29.708773 11033 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "[12/17 00:22:32] ppdet.utils.checkpoint INFO: Finish loading model weights: output/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x/model_final.pdparams\n"
     ]
    }
   ],
   "source": [
    "%cd PaddleDetection/\r\n",
    "# ##########魔改后， svae_txt=True代表不生成json文件！， 反之 生成json文件。 \r\n",
    "# ##########此方法不需要instance_test.json. \r\n",
    "!python tools/infer.py -c /home/aistudio/PaddleDetection/configs/faster_rcnn/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x.yml \\\r\n",
    "                    --infer_dir=/home/aistudio/work/test/IMAGES \\\r\n",
    "                    --output_dir=/home/aistudio/data/infer_output/ \\\r\n",
    "                    --draw_threshold=0.005 \\\r\n",
    "                    -o weights=output/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x/model_final.pdparams  \r\n",
    "                    # --save_txt=True\r\n",
    "\r\n",
    "# !python tools/infer.py     -c /home/aistudio/PaddleDetection/configs/ppyolo/ppyolov2_r50vd_dcn_voc.yml \\\r\n",
    "#     -o weights=output/ppyolov2_r50vd_dcn_voc/best_model.pdparams \\\r\n",
    "#                     --infer_dir=/home/aistudio/work/test/IMAGES \\\r\n",
    "#                     --output_dir=/home/aistudio/data/infer_output/ \\\r\n",
    "#                     --draw_threshold=0.005 \\\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### json转csv， 用于结果提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\r\n",
    "import json\r\n",
    "\r\n",
    "'''\r\n",
    "json格式示例\r\n",
    "[{ \"firstName\":\"Bill\" , \"lastName\":\"Gates\" }, { \"firstName\":\"George\" , \"lastName\":\"Bush\" }, { \"firstName\":\"Thomas\" , \"lastName\":\"Carter\" }]\r\n",
    "'''\r\n",
    "#file:json to csv\r\n",
    "def transcsv(jsonpath, csvpath, threshold):\r\n",
    "    json_file = open(jsonpath, 'r', encoding='utf8')\r\n",
    "    csv_file = open(csvpath, 'w', newline='')\r\n",
    "    #writer = csv.writer(csv_file, delimiter='\\t')\r\n",
    "    writer = csv.writer(csv_file, delimiter=',')\r\n",
    "    #读文件\r\n",
    "    ls = json.load(json_file)  #将json格式的字符串转换成python的数据类型，解码过程\r\n",
    "    # data = [list(ls[0].keys())]  # 获取列名,即key\r\n",
    "    # 只需要把是int的value转为str\r\n",
    "    order = [\"image_id\",\"bbox\",\"category_id\",\"confidence\"]\r\n",
    "    first_line=[\"image_id\",\"bbox\",\"category_id\",\"confidence\"]\r\n",
    "    data=[first_line]\r\n",
    "    for item in ls:\r\n",
    "        #print(\"item[\\\"score\\\"]\", item[\"score\"])\r\n",
    "        if item[\"confidence\"]<threshold:\r\n",
    "            continue\r\n",
    "        else:\r\n",
    "            value_list=[]\r\n",
    "            for itm in order:\r\n",
    "                if(itm ==\"bbox\"):\r\n",
    "                    # 处理\r\n",
    "                    tmp=item[itm]\r\n",
    "                    tmp[2]+=tmp[0]\r\n",
    "                    tmp[3]+=tmp[1]\r\n",
    "                    #print(\"type(tmp[2])\", type(tmp[2]))\r\n",
    "                    value_list.append(tmp)\r\n",
    "                else:\r\n",
    "                    value_list.append(item[itm])\r\n",
    "                # print(value_list)\r\n",
    "            data.append(value_list)\r\n",
    "\r\n",
    "            # for itm in item.values():\r\n",
    "            #     # print(\"type(itm)\", type(itm))\r\n",
    "            #     if isinstance(itm, list):\r\n",
    "            #         # print(\"is list\")\r\n",
    "                    \r\n",
    "            #         tmp=itm\r\n",
    "            #         #print(\"before tmp\", tmp)\r\n",
    "            #         tmp[2]+=tmp[0]\r\n",
    "            #         tmp[3]+=tmp[1]\r\n",
    "            #         #print(\"type(tmp[2])\", type(tmp[2]))\r\n",
    "            #         value_list.append(tmp)\r\n",
    "            #         #print(\"after tmp\", tmp)\r\n",
    "            #     else:\r\n",
    "            #         value_list.append(itm)\r\n",
    "            # data.append(value_list)\r\n",
    "        # data.append(list(item.values()))  # 获取每一行的值value\r\n",
    "        \r\n",
    "    #写入文件\r\n",
    "    for line in data:\r\n",
    "        # print(\"line\", line)\r\n",
    "        # csv_file.write(\",\".join(line) + \"\\n\")  # 以逗号分隔一行的每个元素，最后换行 fw.close() #关闭csv文件\r\n",
    "        writer.writerow(line)\r\n",
    "\r\n",
    "\r\n",
    "    #关闭文件\r\n",
    "    json_file.close()\r\n",
    "    csv_file.close()\r\n",
    "#file:csv to json\r\n",
    "def transjson(jsonpath, csvpath):\r\n",
    "    fw = open(jsonpath, 'w', encoding='utf8')   # 打开csv文件\r\n",
    "    fo = open(csvpath, 'r', newline='')    # 打开csv文件\r\n",
    "\r\n",
    "    ls = []\r\n",
    "    for line in fo:\r\n",
    "        line = line.replace(\"\\n\", \"\")  # 将换行换成空\r\n",
    "        ls.append(line.split(\",\"))  # 以，为分隔符\r\n",
    "    #print(ls)\r\n",
    "    #写入\r\n",
    "    for i in range(1, len(ls)):  # 遍历文件的每一行内容，除了列名\r\n",
    "        ls[i] = dict(zip(ls[0], ls[i]))  # ls[0]为列名，所以为key,ls[i]为value,\r\n",
    "        # zip()是一个内置函数，将两个长度相同的列表组合成一个关系对\r\n",
    "\r\n",
    "    json.dump(ls[1:], fw, sort_keys=True, indent=4)\r\n",
    "    #将Python数据类型转换成json格式，编码过程\r\n",
    "    #默认是顺序存放，sort_keys是对字典元素按照key进行排序\r\n",
    "    #indet参数用语增加数据缩进，使文件更具有可读性\r\n",
    "\r\n",
    "    # 关闭文件\r\n",
    "    fo.close()\r\n",
    "    fw.close()\r\n",
    "# 实际上只需要处理csv文件。 threshold》0.5 的保留。 \r\n",
    "\r\n",
    "# if __name__ == '__main__':\r\n",
    "#     #transcsv('./testcase/my.json', './testcase/my.csv')\r\n",
    "#     transjson('./testcase/write.json', './testcase/my.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trans('/home/aistudio/work/test/result/result.json', '/home/aistudio/work/test/result/submission.csv')\r\n",
    "\r\n",
    "# json.loads读的是单行数据， json.load读的是文件， 多行数据\r\n",
    "# data= json.loads('/home/aistudio/work/test/result/result.json')\r\n",
    "# print(data)\r\n",
    "\r\n",
    "# with open('/home/aistudio/work/test/result/result.json') as f:\r\n",
    "#     result=json.load(f)\r\n",
    "#     print(\"type(result)\", type(result))\r\n",
    "\r\n",
    "transcsv('/home/aistudio/work/test/result/result.json', '/home/aistudio/work/test/result/submission.csv',0)\r\n",
    "# transcsv('/home/aistudio/PaddleDetection-release-2.0-rc/bbox.json', '/home/aistudio/work/test/result/submission.csv',0)\r\n",
    "# transjson('/home/aistudio/paddledetection2-3/submission.json','/home/aistudio/paddledetection2-3/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport json\\n# Tag: 直接两个csv先相加融合。 \\n# image_id.values, distinct找到\\ncsv_path=\"/home/aistudio/work/test/result/submission.csv\"\\ncsv_path1=\"/home/aistudio/paddledetection2-3/submission_process.csv\"\\ndata = pd.read_csv(csv_path)\\ndata1 = pd.read_csv(csv_path1)\\n# 可以\"a\"的形式写成文件。 \\n# for \\n#     df.to_csv(filename, mode=\\'a\\'）\\ndata = pd.concat([data, data1], ignore_index = True)\\n# print(\"data\", data)\\ndf_img_id=data[\"image_id\"].unique()\\n# print(\"df_img_id\", df_img_id)\\n# 遍历image_id,\\nall_ids = []\\nall_boxes = []\\nall_scores = []\\nall_labels = []\\nfor img_id in df_img_id:\\n    # 组建boxes, scores, labels _lists\\n    # print(\"img_id\", img_id)\\n    boxes_list = []\\n    scores_list = []\\n    labels_list = []\\n    for idx,ix in data[data[\"image_id\"]==int(img_id)].iterrows():\\n        # print(\"ix\", ix)\\n        # bbox = json.loads(ix)\\n        \\n        box = json.loads(ix[\"bbox\"])\\n        score = ix[\"confidence\"]\\n        label = ix[\"category_id\"]\\n        boxes_list.append(box)\\n        scores_list.append(score)\\n        labels_list.append(label)\\n    #然后weighted_boxes_fusion， 然后结果放入dataFrame\\n    if run_type == \\'wbf\\':\\n        merged_boxes, merged_scores, merged_labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list,\\n                                                                           weights=weights,\\n                                                                           iou_thr=params[\\'intersection_thr\\'],\\n                                                                           skip_box_thr=params[\\'skip_box_thr\\'],\\n                                                                           conf_type=params[\\'conf_type\\']) \\n\\n    id_list=[img_id] *len(merged_labels)  \\n    all_boxes.append(merged_boxes)\\n    all_scores.append(merged_scores)\\n    all_labels.append(merged_labels)\\n    all_ids.append(ids_list)\\n#根据dataFrame生成一份csv\\nres = pd.DataFrame(all_ids, columns=[\\'image_id\\'])\\nres[\\'bbox\\'] = all_boxes\\nres[\\'category_id\\'] = all_labels\\nres[\\'confidence\\'] = all_scores\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######对csv文件进行threshold后处理（筛选\r\n",
    "import pandas as pd\r\n",
    "'''\r\n",
    "csv_path='/home/aistudio/paddledetection2-3/submission.csv'\r\n",
    "csv_process_path='/home/aistudio/paddledetection2-3/submission_process.csv'\r\n",
    "\r\n",
    "data = pd.read_csv(csv_path)\r\n",
    "# print(\"data\", data[\"confidence\"])\r\n",
    "data2=data[data[\"confidence\"]>=0.5] \r\n",
    "data2.to_csv(csv_process_path, index=False)\r\n",
    "# print(\"data > 0.5\", data[\"confidence\"]>=0.5)\r\n",
    "'''\r\n",
    "\r\n",
    "#####修改confidence =1\r\n",
    "# csv_path=\"/home/aistudio/work/test/result/submission.csv\"\r\n",
    "# data = pd.read_csv(csv_path)\r\n",
    "# # print(\"data\", data[\"confidence\"])\r\n",
    "# # data2=data[data[\"confidence\"]>=0.5] \r\n",
    "# data[\"confidence\"]=1.0\r\n",
    "# data.to_csv(csv_path, index=False)\r\n",
    "\r\n",
    "#########整理csv的顺序\r\n",
    "\r\n",
    "# csv_path=\"/home/aistudio/work/test/result/submission.csv\"\r\n",
    "# # csv_path=\"/home/aistudio/work/fusion_submission.csv\"\r\n",
    "# data = pd.read_csv(csv_path)\r\n",
    "# # print(\"data\", data)\r\n",
    "# sortedlist= data.sort_values(by=\"image_id\")\r\n",
    "# sortedlist.to_csv(csv_path, index=False)\r\n",
    "\r\n",
    "\r\n",
    "import json\r\n",
    "# Tag: 两个csv先相加融合, 然后排序， 生成 concat_submission.csv。 \r\n",
    "# image_id.values, distinct找到\r\n",
    "csv_path=\"/home/aistudio/work/test/result/submission.csv\"\r\n",
    "csv_path1=\"/home/aistudio/work/test/submission42.06.csv\"\r\n",
    "concat_path=\"/home/aistudio/work/test/result/concat_submission.csv\"\r\n",
    "data = pd.read_csv(csv_path)\r\n",
    "data1 = pd.read_csv(csv_path1)\r\n",
    "data = pd.concat([data, data1], ignore_index = True)\r\n",
    "sortedlist= data.sort_values(by=\"image_id\")\r\n",
    "sortedlist.to_csv(concat_path, index=False)\r\n",
    "# print(\"data\", data)\r\n",
    "\r\n",
    "'''\r\n",
    "import json\r\n",
    "# Tag: 直接两个csv先相加融合。 \r\n",
    "# image_id.values, distinct找到\r\n",
    "csv_path=\"/home/aistudio/work/test/result/submission.csv\"\r\n",
    "csv_path1=\"/home/aistudio/paddledetection2-3/submission_process.csv\"\r\n",
    "data = pd.read_csv(csv_path)\r\n",
    "data1 = pd.read_csv(csv_path1)\r\n",
    "# 可以\"a\"的形式写成文件。 \r\n",
    "# for \r\n",
    "#     df.to_csv(filename, mode='a'）\r\n",
    "data = pd.concat([data, data1], ignore_index = True)\r\n",
    "# print(\"data\", data)\r\n",
    "df_img_id=data[\"image_id\"].unique()\r\n",
    "# print(\"df_img_id\", df_img_id)\r\n",
    "# 遍历image_id,\r\n",
    "all_ids = []\r\n",
    "all_boxes = []\r\n",
    "all_scores = []\r\n",
    "all_labels = []\r\n",
    "for img_id in df_img_id:\r\n",
    "    # 组建boxes, scores, labels _lists\r\n",
    "    # print(\"img_id\", img_id)\r\n",
    "    boxes_list = []\r\n",
    "    scores_list = []\r\n",
    "    labels_list = []\r\n",
    "    for idx,ix in data[data[\"image_id\"]==int(img_id)].iterrows():\r\n",
    "        # print(\"ix\", ix)\r\n",
    "        # bbox = json.loads(ix)\r\n",
    "        \r\n",
    "        box = json.loads(ix[\"bbox\"])\r\n",
    "        score = ix[\"confidence\"]\r\n",
    "        label = ix[\"category_id\"]\r\n",
    "        boxes_list.append(box)\r\n",
    "        scores_list.append(score)\r\n",
    "        labels_list.append(label)\r\n",
    "    #然后weighted_boxes_fusion， 然后结果放入dataFrame\r\n",
    "    if run_type == 'wbf':\r\n",
    "        merged_boxes, merged_scores, merged_labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list,\r\n",
    "                                                                           weights=weights,\r\n",
    "                                                                           iou_thr=params['intersection_thr'],\r\n",
    "                                                                           skip_box_thr=params['skip_box_thr'],\r\n",
    "                                                                           conf_type=params['conf_type']) \r\n",
    "\r\n",
    "    id_list=[img_id] *len(merged_labels)  \r\n",
    "    all_boxes.append(merged_boxes)\r\n",
    "    all_scores.append(merged_scores)\r\n",
    "    all_labels.append(merged_labels)\r\n",
    "    all_ids.append(ids_list)\r\n",
    "#根据dataFrame生成一份csv\r\n",
    "res = pd.DataFrame(all_ids, columns=['image_id'])\r\n",
    "res['bbox'] = all_boxes\r\n",
    "res['category_id'] = all_labels\r\n",
    "res['confidence'] = all_scores\r\n",
    "'''\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ===== 以下是我更换ppdet版本之后进行的一些尝试， 无需理会！=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################### 降级为ppdet2.0进行训练测试。 \r\n",
    "#安装依赖\r\n",
    "%cd PaddleDetection-release-2.0-rc/\r\n",
    "!pip install pycocotools\r\n",
    "!pip install scikit-image\r\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd PaddleDetection-release-2.0-rc/\r\n",
    "%env CUDA_VISIBLE_DEVICES=0\r\n",
    "#使用visualDL记录曲线变化\r\n",
    "!python -u tools/train.py \\\r\n",
    "    -c configs/libra_rcnn/libra_rcnn_r50_vd_fpn_1x.yml \\\r\n",
    "    --use_vdl=True \\\r\n",
    "    --vdl_log_dir=vdl_dir/scalar \\\r\n",
    "    -r output/libra_rcnn_r50_vd_fpn_1x/10000.pdparams \\\r\n",
    "    # -o weights=output/libra_rcnn_r50_vd_fpn_1x/10000.pdparams \\\r\n",
    "    --eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############可以直接用此方法保存预测的json文件， 但是需要修改yaml . \r\n",
    "%cd PaddleDetection-release-2.0-rc/\r\n",
    "!python tools/eval.py \\\r\n",
    "    -c configs/libra_rcnn/libra_rcnn_r50_vd_fpn_1x_infer.yaml \\\r\n",
    "    -o weights=output/libra_rcnn_r50_vd_fpn_1x/model_final.pdparams \\\r\n",
    "    save_prediction_only=True\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预览预测的结果, 需要改一改label . \r\n",
    "# 代码不同， 修改infer, trainer代价高。 \r\n",
    "%cd PaddleDetection-release-2.0-rc/\r\n",
    "!python tools/infer.py     -c configs/libra_rcnn/libra_rcnn_r50_vd_fpn_1x_infer.yaml \\\r\n",
    "                    -o weights=output/libra_rcnn_r50_vd_fpn_1x/model_final.pdparams \\\r\n",
    "                    --infer_dir=/home/aistudio/work/test/IMAGES \\\r\n",
    "                    --output_dir=infer_output/ \\\r\n",
    "                    --draw_threshold=0.6 \\\r\n",
    "                    # -o weights=output/faster_rcnn_dcn_x101_vd_64x4d_fpn_1x/model_final.pdparams  \\\r\n",
    "                    #--save_txt=True\r\n",
    "                    #--use_vdl=Ture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "降级为ppdet2.3进行测试。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/paddledetection2-3/PaddleDetection\n"
     ]
    }
   ],
   "source": [
    "%cd paddledetection2-3/PaddleDetection/\r\n",
    "!pip install pycocotools\r\n",
    "!pip install scikit-image\r\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python tools/infer.py -c configs/ppyolo/ppyolov2_r50vd_dcn_voc.yml \\\r\n",
    "-o weights=../ppyolov2_r50vd_dcn_voc/1394 \\\r\n",
    "--infer_img=/home/aistudio/work/test/IMAGES/1400.jpg \\\r\n",
    "--output_dir=/home/aistudio/data/steel/infer_output\\\r\n",
    "--draw_threshold=0.005 --save_txt=True\r\n",
    "\r\n",
    "# --draw_threshold=0.5 --save_txt=True\r\n",
    "# --infer_img=/home/aistudio/work/test/IMAGES/1400.jpg \\\r\n",
    "# --infer_dir=/home/aistudio/work/test/IMAGES \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
